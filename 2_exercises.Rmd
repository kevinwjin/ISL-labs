---
title: "Chapter 2 Exercises"
author: "Kevin Jin"
date: '2022-05-26'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Conceptual
1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.
    a)
    b)
    c)
    d)

2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.
    a)
    b)
    c)

3. We now revisit the bias-variance decomposition.

4. You will now think of some real-life applications for statistical learning.

5. What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred? 

6. Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a non-parametric approach)? What are its disadvantages?

7. The table below provides a training data set containing six observations, three predictors, and one qualitative response variable. Suppose we wish to use this data set to make a prediction for $Y$ when
$X_1 = X_2 = X_3 = 0$ using $K$-nearest neighbors.
    a) Compute the Euclidean distance between each observation and the test point, $X_1 = X_2 = X_3 = 0$.
    b) What is our prediction with $K=1$? Why?
    c) What is our prediction with $K=3$? Why?
    d) If the Bayes decision boundary in this problem is highly non-linear, then would we expect the *best* value for $K$ to be large or small? Why?

## Applied

8. This exercise relates to the `College` data set, which can be found in the file `College.csv` on the book website. It contains a number of variables for 777 different universities and colleges in the US. 
```{r college}
college <- read.csv("College.csv")
rownames(college) <- college[, 1] # name each row with college name
college <- college [, -1] # delete original names column

pairs(college[, 2:11]) # scatterplot matrix of first ten variables

```

9.

10.

